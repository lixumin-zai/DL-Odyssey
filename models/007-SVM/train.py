import torch
import torch.nn as nn
import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
import numpy as np
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, Any, Tuple, Optional
import os
from datetime import datetime

# å¯¼å…¥æˆ‘ä»¬è‡ªå®šä¹‰çš„æ¨¡å—
from model import SVMModel, MultiClassSVM
from dataset import (
    SyntheticDataGenerator, 
    RealWorldDataLoader, 
    create_data_loaders,
    visualize_2d_data,
    analyze_dataset
)

class SVMLightningModule(pl.LightningModule):
    """
    SVMçš„PyTorch Lightningæ¨¡å—
    
    è¿™ä¸ªç±»å°†SVMæ¨¡å‹åŒ…è£…ä¸ºLightningæ¨¡å—ï¼Œæä¾›æ ‡å‡†åŒ–çš„è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æµç¨‹
    """
    
    def __init__(self, 
                 kernel: str = 'rbf',
                 C: float = 1.0,
                 gamma: str = 'scale',
                 learning_rate: float = 0.001,
                 **kwargs):
        """
        åˆå§‹åŒ–SVM Lightningæ¨¡å—
        
        Args:
            kernel: æ ¸å‡½æ•°ç±»å‹
            C: æ­£åˆ™åŒ–å‚æ•°
            gamma: RBFæ ¸å‚æ•°
            learning_rate: å­¦ä¹ ç‡ï¼ˆè™½ç„¶SVMä¸ä½¿ç”¨æ¢¯åº¦ä¸‹é™ï¼Œä½†ä¿ç•™ç”¨äºå…¼å®¹æ€§ï¼‰
            **kwargs: å…¶ä»–SVMå‚æ•°
        """
        super().__init__()
        
        # ä¿å­˜è¶…å‚æ•°åˆ°Lightningçš„hparams
        self.save_hyperparameters()  # è‡ªåŠ¨ä¿å­˜æ‰€æœ‰åˆå§‹åŒ–å‚æ•°
        
        # åˆ›å»ºSVMæ¨¡å‹å®ä¾‹
        self.svm_model = SVMModel(
            kernel=kernel,
            C=C, 
            gamma=gamma,
            **kwargs
        )
        
        # å­˜å‚¨è®­ç»ƒå’ŒéªŒè¯æŒ‡æ ‡
        self.train_metrics = []  # è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŒ‡æ ‡è®°å½•
        self.val_metrics = []    # éªŒè¯è¿‡ç¨‹ä¸­çš„æŒ‡æ ‡è®°å½•
        
        # æ ‡å¿—ä½ï¼Œè¡¨ç¤ºæ¨¡å‹æ˜¯å¦å·²ç»è®­ç»ƒ
        self.model_fitted = False
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            x: è¾“å…¥ç‰¹å¾ [batch_size, n_features]
            
        Returns:
            output: æ¨¡å‹è¾“å‡º [batch_size]
        """
        if not self.model_fitted:
            # å¦‚æœæ¨¡å‹è¿˜æ²¡æœ‰è®­ç»ƒï¼Œè¿”å›é›¶å‘é‡
            return torch.zeros(x.shape[0], device=x.device)
        
        # ä½¿ç”¨è®­ç»ƒå¥½çš„SVMè¿›è¡Œé¢„æµ‹
        return self.svm_model.decision_function(x)
    
    def training_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> Dict[str, Any]:
        """
        è®­ç»ƒæ­¥éª¤
        
        æ³¨æ„ï¼šSVMä½¿ç”¨SMOç®—æ³•è®­ç»ƒï¼Œä¸æ˜¯åŸºäºæ¢¯åº¦çš„ä¼˜åŒ–ï¼Œ
        æ‰€ä»¥è¿™é‡Œä¸»è¦ç”¨äºè®°å½•è®­ç»ƒè¿‡ç¨‹å’ŒæŒ‡æ ‡
        
        Args:
            batch: ä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ® (features, labels)
            batch_idx: æ‰¹æ¬¡ç´¢å¼•
            
        Returns:
            åŒ…å«æŸå¤±å’ŒæŒ‡æ ‡çš„å­—å…¸
        """
        features, labels = batch  # è§£åŒ…æ‰¹æ¬¡æ•°æ®
        
        # å¦‚æœæ˜¯ç¬¬ä¸€ä¸ªepochçš„ç¬¬ä¸€ä¸ªbatchï¼Œè¿›è¡ŒSVMè®­ç»ƒ
        if not self.model_fitted and batch_idx == 0 and self.current_epoch == 0:
            print("\nå¼€å§‹SVMæ¨¡å‹è®­ç»ƒ...")
            
            # æ”¶é›†æ‰€æœ‰è®­ç»ƒæ•°æ®è¿›è¡ŒSVMè®­ç»ƒ
            # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬éœ€è¦è®¿é—®å®Œæ•´çš„è®­ç»ƒæ•°æ®é›†
            train_dataloader = self.trainer.train_dataloader
            
            # æ”¶é›†æ‰€æœ‰è®­ç»ƒæ•°æ®
            all_features = []
            all_labels = []
            
            for batch_data in train_dataloader:
                batch_features, batch_labels = batch_data
                all_features.append(batch_features)
                all_labels.append(batch_labels)
            
            # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡çš„æ•°æ®
            X_train = torch.cat(all_features, dim=0)  # æ‹¼æ¥æ‰€æœ‰ç‰¹å¾
            y_train = torch.cat(all_labels, dim=0)    # æ‹¼æ¥æ‰€æœ‰æ ‡ç­¾
            
            print(f"è®­ç»ƒæ•°æ®å½¢çŠ¶: X={X_train.shape}, y={y_train.shape}")
            
            # è®­ç»ƒSVMæ¨¡å‹
            self.svm_model.fit(X_train, y_train)
            self.model_fitted = True  # æ ‡è®°æ¨¡å‹å·²è®­ç»ƒ
            
            print("SVMæ¨¡å‹è®­ç»ƒå®Œæˆï¼")
        
        # å¦‚æœæ¨¡å‹å·²è®­ç»ƒï¼Œè®¡ç®—é¢„æµ‹å’ŒæŒ‡æ ‡
        if self.model_fitted:
            # è¿›è¡Œé¢„æµ‹
            predictions = self.svm_model.predict(features)
            
            # è®¡ç®—å‡†ç¡®ç‡
            accuracy = (predictions == labels).float().mean()
            
            # è®¡ç®—ä¸€ä¸ªè™šæ‹Ÿçš„æŸå¤±ï¼ˆSVMä¸ä½¿ç”¨æŸå¤±å‡½æ•°è®­ç»ƒï¼‰
            # è¿™é‡Œä½¿ç”¨1-accuracyä½œä¸ºæŸå¤±ï¼Œä»…ç”¨äºç›‘æ§
            loss = 1.0 - accuracy
            
            # è®°å½•æŒ‡æ ‡
            self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)
            self.log('train_accuracy', accuracy, on_step=True, on_epoch=True, prog_bar=True)
            
            return {
                'loss': loss,
                'accuracy': accuracy,
                'predictions': predictions,
                'targets': labels
            }
        else:
            # æ¨¡å‹æœªè®­ç»ƒæ—¶è¿”å›è™šæ‹ŸæŸå¤±
            dummy_loss = torch.tensor(1.0, requires_grad=True)
            return {'loss': dummy_loss}
    
    def validation_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> Dict[str, Any]:
        """
        éªŒè¯æ­¥éª¤
        
        Args:
            batch: ä¸€ä¸ªæ‰¹æ¬¡çš„éªŒè¯æ•°æ®
            batch_idx: æ‰¹æ¬¡ç´¢å¼•
            
        Returns:
            åŒ…å«éªŒè¯æŒ‡æ ‡çš„å­—å…¸
        """
        features, labels = batch
        
        if not self.model_fitted:
            # å¦‚æœæ¨¡å‹è¿˜æ²¡è®­ç»ƒï¼Œè¿”å›è™šæ‹ŸæŒ‡æ ‡
            return {
                'val_loss': torch.tensor(1.0),
                'val_accuracy': torch.tensor(0.0)
            }
        
        # è¿›è¡Œé¢„æµ‹
        predictions = self.svm_model.predict(features)
        decision_values = self.svm_model.decision_function(features)
        
        # è®¡ç®—å‡†ç¡®ç‡
        accuracy = (predictions == labels).float().mean()
        
        # è®¡ç®—è™šæ‹ŸæŸå¤±
        val_loss = 1.0 - accuracy
        
        # è®°å½•éªŒè¯æŒ‡æ ‡
        self.log('val_loss', val_loss, on_step=False, on_epoch=True, prog_bar=True)
        self.log('val_accuracy', accuracy, on_step=False, on_epoch=True, prog_bar=True)
        
        return {
            'val_loss': val_loss,
            'val_accuracy': accuracy,
            'predictions': predictions,
            'targets': labels,
            'decision_values': decision_values
        }
    
    def test_step(self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int) -> Dict[str, Any]:
        """
        æµ‹è¯•æ­¥éª¤
        
        Args:
            batch: ä¸€ä¸ªæ‰¹æ¬¡çš„æµ‹è¯•æ•°æ®
            batch_idx: æ‰¹æ¬¡ç´¢å¼•
            
        Returns:
            åŒ…å«æµ‹è¯•æŒ‡æ ‡çš„å­—å…¸
        """
        features, labels = batch
        
        if not self.model_fitted:
            return {
                'test_loss': torch.tensor(1.0),
                'test_accuracy': torch.tensor(0.0)
            }
        
        # è¿›è¡Œé¢„æµ‹
        predictions = self.svm_model.predict(features)
        decision_values = self.svm_model.decision_function(features)
        
        # è®¡ç®—å‡†ç¡®ç‡
        accuracy = (predictions == labels).float().mean()
        test_loss = 1.0 - accuracy
        
        # è®°å½•æµ‹è¯•æŒ‡æ ‡
        self.log('test_loss', test_loss, on_step=False, on_epoch=True)
        self.log('test_accuracy', accuracy, on_step=False, on_epoch=True)
        
        return {
            'test_loss': test_loss,
            'test_accuracy': accuracy,
            'predictions': predictions,
            'targets': labels,
            'decision_values': decision_values
        }
    
    def configure_optimizers(self):
        """
        é…ç½®ä¼˜åŒ–å™¨
        
        æ³¨æ„ï¼šSVMä¸ä½¿ç”¨æ¢¯åº¦ä¼˜åŒ–ï¼Œè¿™é‡Œè¿”å›ä¸€ä¸ªè™šæ‹Ÿä¼˜åŒ–å™¨ä»¥æ»¡è¶³Lightningè¦æ±‚
        """
        # åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿå‚æ•°ç”¨äºä¼˜åŒ–å™¨
        dummy_param = nn.Parameter(torch.tensor(0.0))
        self.register_parameter('dummy', dummy_param)
        
        # è¿”å›ä¸€ä¸ªè™šæ‹Ÿä¼˜åŒ–å™¨
        optimizer = torch.optim.Adam([dummy_param], lr=self.hparams.learning_rate)
        return optimizer
    
    def on_train_epoch_end(self):
        """
        è®­ç»ƒepochç»“æŸæ—¶çš„å›è°ƒ
        """
        if self.model_fitted:
            # è·å–å½“å‰epochçš„è®­ç»ƒæŒ‡æ ‡
            train_loss = self.trainer.callback_metrics.get('train_loss_epoch', 0)
            train_acc = self.trainer.callback_metrics.get('train_accuracy_epoch', 0)
            
            # è®°å½•åˆ°è®­ç»ƒæŒ‡æ ‡åˆ—è¡¨
            self.train_metrics.append({
                'epoch': self.current_epoch,
                'loss': float(train_loss),
                'accuracy': float(train_acc)
            })
    
    def on_validation_epoch_end(self):
        """
        éªŒè¯epochç»“æŸæ—¶çš„å›è°ƒ
        """
        if self.model_fitted:
            # è·å–å½“å‰epochçš„éªŒè¯æŒ‡æ ‡
            val_loss = self.trainer.callback_metrics.get('val_loss', 0)
            val_acc = self.trainer.callback_metrics.get('val_accuracy', 0)
            
            # è®°å½•åˆ°éªŒè¯æŒ‡æ ‡åˆ—è¡¨
            self.val_metrics.append({
                'epoch': self.current_epoch,
                'loss': float(val_loss),
                'accuracy': float(val_acc)
            })
    
    def get_support_vectors_info(self) -> Dict[str, Any]:
        """
        è·å–æ”¯æŒå‘é‡ä¿¡æ¯
        
        Returns:
            åŒ…å«æ”¯æŒå‘é‡ä¿¡æ¯çš„å­—å…¸
        """
        if not self.model_fitted:
            return {"error": "æ¨¡å‹å°šæœªè®­ç»ƒ"}
        
        support_vectors, support_labels, alphas = self.svm_model.get_support_vectors()
        
        return {
            'n_support_vectors': len(support_vectors),
            'support_vectors': support_vectors,
            'support_labels': support_labels,
            'alphas': alphas,
            'support_ratio': len(support_vectors) / len(self.svm_model.X_train) * 100
        }


class SVMTrainer:
    """
    SVMè®­ç»ƒå™¨ç±»
    
    æä¾›å®Œæ•´çš„SVMè®­ç»ƒã€è¯„ä¼°å’Œå¯è§†åŒ–åŠŸèƒ½
    """
    
    def __init__(self, 
                 kernel: str = 'rbf',
                 C: float = 1.0,
                 gamma: str = 'scale',
                 max_epochs: int = 10,
                 accelerator: str = 'auto'):
        """
        åˆå§‹åŒ–SVMè®­ç»ƒå™¨
        
        Args:
            kernel: æ ¸å‡½æ•°ç±»å‹
            C: æ­£åˆ™åŒ–å‚æ•°
            gamma: RBFæ ¸å‚æ•°
            max_epochs: æœ€å¤§è®­ç»ƒè½®æ•°
            accelerator: åŠ é€Ÿå™¨ç±»å‹
        """
        self.kernel = kernel
        self.C = C
        self.gamma = gamma
        self.max_epochs = max_epochs
        self.accelerator = accelerator
        
        # åˆ›å»ºç»“æœä¿å­˜ç›®å½•
        self.results_dir = f"svm_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        os.makedirs(self.results_dir, exist_ok=True)
        
        print(f"ç»“æœå°†ä¿å­˜åˆ°: {self.results_dir}")
    
    def train(self, 
              train_loader, 
              val_loader, 
              test_loader=None) -> SVMLightningModule:
        """
        è®­ç»ƒSVMæ¨¡å‹
        
        Args:
            train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
            val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
            test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            è®­ç»ƒå¥½çš„Lightningæ¨¡å—
        """
        print("\n" + "="*60)
        print("å¼€å§‹SVMæ¨¡å‹è®­ç»ƒ")
        print("="*60)
        
        # åˆ›å»ºLightningæ¨¡å—
        model = SVMLightningModule(
            kernel=self.kernel,
            C=self.C,
            gamma=self.gamma
        )
        
        # é…ç½®å›è°ƒå‡½æ•°
        callbacks = [
            # æ¨¡å‹æ£€æŸ¥ç‚¹å›è°ƒ
            ModelCheckpoint(
                dirpath=self.results_dir,
                filename='best_svm_model',
                monitor='val_accuracy',  # ç›‘æ§éªŒè¯å‡†ç¡®ç‡
                mode='max',             # æœ€å¤§åŒ–å‡†ç¡®ç‡
                save_top_k=1,           # åªä¿å­˜æœ€å¥½çš„æ¨¡å‹
                verbose=True
            ),
            # æ—©åœå›è°ƒ
            EarlyStopping(
                monitor='val_accuracy',
                patience=5,             # 5ä¸ªepochæ²¡æœ‰æ”¹å–„å°±åœæ­¢
                mode='max',
                verbose=True
            )
        ]
        
        # é…ç½®æ—¥å¿—è®°å½•å™¨
        logger = TensorBoardLogger(
            save_dir=self.results_dir,
            name='svm_logs'
        )
        
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = pl.Trainer(
            max_epochs=self.max_epochs,
            accelerator=self.accelerator,
            callbacks=callbacks,
            logger=logger,
            enable_progress_bar=True,
            log_every_n_steps=1
        )
        
        # å¼€å§‹è®­ç»ƒ
        print(f"\nä½¿ç”¨å‚æ•°è®­ç»ƒSVM:")
        print(f"  - æ ¸å‡½æ•°: {self.kernel}")
        print(f"  - Cå‚æ•°: {self.C}")
        print(f"  - Gamma: {self.gamma}")
        print(f"  - æœ€å¤§è½®æ•°: {self.max_epochs}")
        
        trainer.fit(model, train_loader, val_loader)
        
        # å¦‚æœæœ‰æµ‹è¯•æ•°æ®ï¼Œè¿›è¡Œæµ‹è¯•
        if test_loader is not None:
            print("\nå¼€å§‹æ¨¡å‹æµ‹è¯•...")
            trainer.test(model, test_loader)
        
        print("\nè®­ç»ƒå®Œæˆï¼")
        return model
    
    def evaluate_model(self, 
                      model: SVMLightningModule, 
                      test_loader,
                      class_names: Optional[list] = None) -> Dict[str, Any]:
        """
        è¯„ä¼°æ¨¡å‹æ€§èƒ½
        
        Args:
            model: è®­ç»ƒå¥½çš„æ¨¡å‹
            test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
            class_names: ç±»åˆ«åç§°åˆ—è¡¨
            
        Returns:
            è¯„ä¼°ç»“æœå­—å…¸
        """
        print("\n" + "="*50)
        print("æ¨¡å‹æ€§èƒ½è¯„ä¼°")
        print("="*50)
        
        if not model.model_fitted:
            print("é”™è¯¯ï¼šæ¨¡å‹å°šæœªè®­ç»ƒ")
            return {}
        
        # æ”¶é›†æ‰€æœ‰é¢„æµ‹ç»“æœ
        all_predictions = []
        all_targets = []
        all_decision_values = []
        
        model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        
        with torch.no_grad():  # ç¦ç”¨æ¢¯åº¦è®¡ç®—
            for batch in test_loader:
                features, labels = batch
                
                # è¿›è¡Œé¢„æµ‹
                predictions = model.svm_model.predict(features)
                decision_values = model.svm_model.decision_function(features)
                
                # æ”¶é›†ç»“æœ
                all_predictions.extend(predictions.cpu().numpy())
                all_targets.extend(labels.cpu().numpy())
                all_decision_values.extend(decision_values.cpu().numpy())
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        y_true = np.array(all_targets)
        y_pred = np.array(all_predictions)
        decision_scores = np.array(all_decision_values)
        
        # è®¡ç®—å„ç§æŒ‡æ ‡
        accuracy = accuracy_score(y_true, y_pred)
        
        print(f"\nğŸ“Š æ•´ä½“æ€§èƒ½:")
        print(f"  - å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
        print(f"  - æµ‹è¯•æ ·æœ¬æ•°: {len(y_true)}")
        print(f"  - æ­£ç¡®é¢„æµ‹æ•°: {np.sum(y_true == y_pred)}")
        
        # ç”Ÿæˆåˆ†ç±»æŠ¥å‘Š
        if class_names is None:
            class_names = [f'Class {i}' for i in np.unique(y_true)]
        
        print(f"\nğŸ“‹ è¯¦ç»†åˆ†ç±»æŠ¥å‘Š:")
        report = classification_report(y_true, y_pred, target_names=class_names)
        print(report)
        
        # ç”Ÿæˆæ··æ·†çŸ©é˜µ
        cm = confusion_matrix(y_true, y_pred)
        print(f"\nğŸ”¢ æ··æ·†çŸ©é˜µ:")
        print(cm)
        
        # å¯è§†åŒ–æ··æ·†çŸ©é˜µ
        self._plot_confusion_matrix(cm, class_names)
        
        # è·å–æ”¯æŒå‘é‡ä¿¡æ¯
        sv_info = model.get_support_vectors_info()
        print(f"\nğŸ¯ æ”¯æŒå‘é‡ä¿¡æ¯:")
        print(f"  - æ”¯æŒå‘é‡æ•°é‡: {sv_info['n_support_vectors']}")
        print(f"  - æ”¯æŒå‘é‡æ¯”ä¾‹: {sv_info['support_ratio']:.2f}%")
        
        # ä¿å­˜è¯„ä¼°ç»“æœ
        results = {
            'accuracy': accuracy,
            'classification_report': report,
            'confusion_matrix': cm,
            'support_vectors_info': sv_info,
            'predictions': y_pred,
            'true_labels': y_true,
            'decision_scores': decision_scores
        }
        
        return results
    
    def _plot_confusion_matrix(self, cm: np.ndarray, class_names: list):
        """
        ç»˜åˆ¶æ··æ·†çŸ©é˜µçƒ­åŠ›å›¾
        
        Args:
            cm: æ··æ·†çŸ©é˜µ
            class_names: ç±»åˆ«åç§°åˆ—è¡¨
        """
        plt.figure(figsize=(8, 6))
        
        # åˆ›å»ºçƒ­åŠ›å›¾
        sns.heatmap(cm, 
                   annot=True,           # æ˜¾ç¤ºæ•°å€¼
                   fmt='d',              # æ•´æ•°æ ¼å¼
                   cmap='Blues',         # é¢œè‰²æ˜ å°„
                   xticklabels=class_names,
                   yticklabels=class_names)
        
        plt.title('æ··æ·†çŸ©é˜µ', fontsize=14, fontweight='bold')
        plt.xlabel('é¢„æµ‹æ ‡ç­¾', fontsize=12)
        plt.ylabel('çœŸå®æ ‡ç­¾', fontsize=12)
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        save_path = os.path.join(self.results_dir, 'confusion_matrix.png')
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"æ··æ·†çŸ©é˜µå·²ä¿å­˜åˆ°: {save_path}")
        
        plt.show()
    
    def visualize_decision_boundary(self, 
                                  model: SVMLightningModule,
                                  X: np.ndarray, 
                                  y: np.ndarray,
                                  title: str = "SVMå†³ç­–è¾¹ç•Œ"):
        """
        å¯è§†åŒ–SVMçš„å†³ç­–è¾¹ç•Œï¼ˆä»…é€‚ç”¨äº2Dæ•°æ®ï¼‰
        
        Args:
            model: è®­ç»ƒå¥½çš„æ¨¡å‹
            X: ç‰¹å¾æ•°æ® [n_samples, 2]
            y: æ ‡ç­¾æ•°æ® [n_samples]
            title: å›¾è¡¨æ ‡é¢˜
        """
        if X.shape[1] != 2:
            print(f"è­¦å‘Šï¼šæ•°æ®ç»´åº¦ä¸º{X.shape[1]}ï¼Œæ— æ³•å¯è§†åŒ–å†³ç­–è¾¹ç•Œ")
            return
        
        if not model.model_fitted:
            print("é”™è¯¯ï¼šæ¨¡å‹å°šæœªè®­ç»ƒ")
            return
        
        print("\nç»˜åˆ¶å†³ç­–è¾¹ç•Œ...")
        
        # åˆ›å»ºç½‘æ ¼ç‚¹
        h = 0.02  # ç½‘æ ¼æ­¥é•¿
        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
        xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                            np.arange(y_min, y_max, h))
        
        # å¯¹ç½‘æ ¼ç‚¹è¿›è¡Œé¢„æµ‹
        grid_points = torch.FloatTensor(np.c_[xx.ravel(), yy.ravel()])
        
        with torch.no_grad():
            Z = model.svm_model.decision_function(grid_points)
            Z = Z.cpu().numpy().reshape(xx.shape)
        
        # åˆ›å»ºå›¾è¡¨
        plt.figure(figsize=(12, 8))
        
        # ç»˜åˆ¶å†³ç­–è¾¹ç•Œ
        plt.contourf(xx, yy, Z, levels=50, alpha=0.8, cmap=plt.cm.RdYlBu)
        plt.contour(xx, yy, Z, levels=[0], linewidths=2, colors='black', linestyles='--')
        
        # ç»˜åˆ¶æ•°æ®ç‚¹
        unique_classes = np.unique(y)
        colors = ['red', 'blue', 'green', 'purple', 'orange']
        
        for i, cls in enumerate(unique_classes):
            mask = y == cls
            plt.scatter(X[mask, 0], X[mask, 1], 
                       c=colors[i % len(colors)], 
                       label=f'Class {cls}',
                       s=50, alpha=0.9, edgecolors='black')
        
        # ç»˜åˆ¶æ”¯æŒå‘é‡
        sv_info = model.get_support_vectors_info()
        if 'support_vectors' in sv_info:
            support_vectors = sv_info['support_vectors'].cpu().numpy()
            plt.scatter(support_vectors[:, 0], support_vectors[:, 1],
                       s=200, facecolors='none', edgecolors='black', 
                       linewidths=2, label='Support Vectors')
        
        plt.xlabel('Feature 1', fontsize=12)
        plt.ylabel('Feature 2', fontsize=12)
        plt.title(title, fontsize=14, fontweight='bold')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        save_path = os.path.join(self.results_dir, 'decision_boundary.png')
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"å†³ç­–è¾¹ç•Œå›¾å·²ä¿å­˜åˆ°: {save_path}")
        
        plt.show()


def run_svm_experiment(dataset_name: str = 'circles',
                      kernel: str = 'rbf',
                      C: float = 1.0,
                      gamma: str = 'scale'):
    """
    è¿è¡Œå®Œæ•´çš„SVMå®éªŒ
    
    Args:
        dataset_name: æ•°æ®é›†åç§° ('linear', 'circles', 'moons', 'cancer', 'wine')
        kernel: æ ¸å‡½æ•°ç±»å‹
        C: æ­£åˆ™åŒ–å‚æ•°
        gamma: RBFæ ¸å‚æ•°
    """
    print("\n" + "="*80)
    print(f"SVMå®éªŒ: {dataset_name.upper()} æ•°æ®é›†")
    print("="*80)
    
    # 1. åŠ è½½æ•°æ®
    print("\n1ï¸âƒ£ åŠ è½½æ•°æ®é›†...")
    
    if dataset_name == 'linear':
        X, y = SyntheticDataGenerator.generate_linear_separable(n_samples=500)
        class_names = ['Class 0', 'Class 1']
    elif dataset_name == 'circles':
        X, y = SyntheticDataGenerator.generate_circles(n_samples=500)
        class_names = ['Inner Circle', 'Outer Circle']
    elif dataset_name == 'moons':
        X, y = SyntheticDataGenerator.generate_moons(n_samples=500)
        class_names = ['Moon 1', 'Moon 2']
    elif dataset_name == 'cancer':
        X, y, feature_names = RealWorldDataLoader.load_breast_cancer()
        class_names = ['Malignant', 'Benign']
    elif dataset_name == 'wine':
        X, y, feature_names = RealWorldDataLoader.load_wine()
        class_names = ['Class 0', 'Class 1', 'Class 2']
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®é›†: {dataset_name}")
    
    # åˆ†ææ•°æ®é›†
    analyze_dataset(X, y)
    
    # å¯è§†åŒ–2Dæ•°æ®
    if X.shape[1] == 2:
        visualize_2d_data(X, y, title=f"{dataset_name.title()} Dataset")
    
    # 2. åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print("\n2ï¸âƒ£ åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    train_loader, val_loader, train_dataset, test_dataset = create_data_loaders(
        X, y, test_size=0.2, batch_size=64, normalize=True
    )
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨
    from torch.utils.data import DataLoader
    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)
    
    # 3. è®­ç»ƒæ¨¡å‹
    print("\n3ï¸âƒ£ è®­ç»ƒSVMæ¨¡å‹...")
    trainer = SVMTrainer(
        kernel=kernel,
        C=C,
        gamma=gamma,
        max_epochs=5  # SVMåªéœ€è¦å°‘é‡epoch
    )
    
    model = trainer.train(train_loader, val_loader, test_loader)
    
    # 4. è¯„ä¼°æ¨¡å‹
    print("\n4ï¸âƒ£ è¯„ä¼°æ¨¡å‹æ€§èƒ½...")
    results = trainer.evaluate_model(model, test_loader, class_names)
    
    # 5. å¯è§†åŒ–å†³ç­–è¾¹ç•Œï¼ˆä»…é€‚ç”¨äº2Dæ•°æ®ï¼‰
    if X.shape[1] == 2:
        print("\n5ï¸âƒ£ å¯è§†åŒ–å†³ç­–è¾¹ç•Œ...")
        # ä½¿ç”¨æµ‹è¯•æ•°æ®è¿›è¡Œå¯è§†åŒ–
        X_test = test_dataset.X.numpy()
        y_test = test_dataset.y.numpy()
        trainer.visualize_decision_boundary(
            model, X_test, y_test, 
            title=f"SVM Decision Boundary ({dataset_name.title()}, {kernel} kernel)"
        )
    
    print("\n" + "="*80)
    print("å®éªŒå®Œæˆï¼")
    print("="*80)
    
    return model, results


if __name__ == "__main__":
    # è®¾ç½®éšæœºç§å­ç¡®ä¿ç»“æœå¯é‡ç°
    torch.manual_seed(42)
    np.random.seed(42)
    
    print("SVMè®­ç»ƒæ¨¡å—æ¼”ç¤º")
    print("="*50)
    
    # è¿è¡Œä¸åŒæ•°æ®é›†çš„å®éªŒ
    experiments = [
        {'dataset': 'circles', 'kernel': 'rbf', 'C': 1.0},
        {'dataset': 'moons', 'kernel': 'rbf', 'C': 1.0},
        {'dataset': 'linear', 'kernel': 'linear', 'C': 1.0},
    ]
    
    for exp in experiments:
        try:
            print(f"\nğŸš€ å¼€å§‹å®éªŒ: {exp}")
            model, results = run_svm_experiment(**exp)
            print(f"âœ… å®éªŒå®Œæˆï¼Œå‡†ç¡®ç‡: {results['accuracy']:.4f}")
        except Exception as e:
            print(f"âŒ å®éªŒå¤±è´¥: {e}")
    
    print("\nğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆï¼")