#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SVMæ¨¡å‹ä½¿ç”¨ç¤ºä¾‹

è¿™ä¸ªæ–‡ä»¶å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨æˆ‘ä»¬å®ç°çš„SVMæ¨¡å‹è¿›è¡Œå„ç§æœºå™¨å­¦ä¹ ä»»åŠ¡ï¼Œ
åŒ…æ‹¬äºŒåˆ†ç±»ã€å¤šåˆ†ç±»ã€å‚æ•°è°ƒä¼˜ç­‰ã€‚

ä½œè€…: DL-Odyssey
æ—¥æœŸ: 2024
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, classification_report
import warnings
warnings.filterwarnings('ignore')  # å¿½ç•¥è­¦å‘Šä¿¡æ¯

# å¯¼å…¥æˆ‘ä»¬è‡ªå®šä¹‰çš„æ¨¡å—
from model import SVMModel, MultiClassSVM, create_svm_model
from dataset import (
    SyntheticDataGenerator, 
    RealWorldDataLoader, 
    create_data_loaders,
    visualize_2d_data,
    analyze_dataset
)
from train import SVMTrainer, run_svm_experiment

def example_1_basic_binary_classification():
    """
    ç¤ºä¾‹1: åŸºç¡€äºŒåˆ†ç±»ä»»åŠ¡
    
    æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨SVMè¿›è¡Œç®€å•çš„äºŒåˆ†ç±»ä»»åŠ¡
    """
    print("\n" + "="*60)
    print("ç¤ºä¾‹1: åŸºç¡€äºŒåˆ†ç±»ä»»åŠ¡")
    print("="*60)
    
    # 1. ç”Ÿæˆçº¿æ€§å¯åˆ†çš„æ•°æ®
    print("\nğŸ“Š ç”Ÿæˆçº¿æ€§å¯åˆ†æ•°æ®...")
    X, y = SyntheticDataGenerator.generate_linear_separable(
        n_samples=200,    # 200ä¸ªæ ·æœ¬
        n_features=2,     # 2ä¸ªç‰¹å¾ï¼ˆä¾¿äºå¯è§†åŒ–ï¼‰
        random_state=42   # å›ºå®šéšæœºç§å­
    )
    
    # åˆ†ææ•°æ®é›†
    analyze_dataset(X, y)
    
    # å¯è§†åŒ–åŸå§‹æ•°æ®
    visualize_2d_data(X, y, title="åŸå§‹æ•°æ®åˆ†å¸ƒ")
    
    # 2. åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print("\nğŸ”„ åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    train_loader, val_loader, train_dataset, test_dataset = create_data_loaders(
        X, y, 
        test_size=0.3,     # 30%ä½œä¸ºæµ‹è¯•é›†
        batch_size=32,     # æ‰¹æ¬¡å¤§å°
        normalize=True     # æ ‡å‡†åŒ–ç‰¹å¾
    )
    
    # 3. åˆ›å»ºå¹¶è®­ç»ƒSVMæ¨¡å‹
    print("\nğŸ¤– åˆ›å»ºSVMæ¨¡å‹...")
    svm_model = create_svm_model(
        kernel='linear',   # ä½¿ç”¨çº¿æ€§æ ¸ï¼ˆé€‚åˆçº¿æ€§å¯åˆ†æ•°æ®ï¼‰
        C=1.0             # æ­£åˆ™åŒ–å‚æ•°
    )
    
    # è·å–è®­ç»ƒæ•°æ®
    X_train = train_dataset.X
    y_train = train_dataset.y
    
    print("\nğŸš€ å¼€å§‹è®­ç»ƒ...")
    svm_model.fit(X_train, y_train)
    
    # 4. è¿›è¡Œé¢„æµ‹
    print("\nğŸ”® è¿›è¡Œé¢„æµ‹...")
    X_test = test_dataset.X
    y_test = test_dataset.y
    
    predictions = svm_model.predict(X_test)
    decision_values = svm_model.decision_function(X_test)
    
    # 5. è¯„ä¼°æ€§èƒ½
    accuracy = accuracy_score(y_test.numpy(), predictions.numpy())
    print(f"\nğŸ“ˆ æ¨¡å‹æ€§èƒ½:")
    print(f"  - æµ‹è¯•å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
    
    # è·å–æ”¯æŒå‘é‡ä¿¡æ¯
    support_vectors, support_labels, alphas = svm_model.get_support_vectors()
    print(f"  - æ”¯æŒå‘é‡æ•°é‡: {len(support_vectors)}")
    print(f"  - æ”¯æŒå‘é‡æ¯”ä¾‹: {len(support_vectors)/len(X_train)*100:.2f}%")
    
    # 6. å¯è§†åŒ–ç»“æœ
    print("\nğŸ¨ å¯è§†åŒ–å†³ç­–è¾¹ç•Œ...")
    visualize_decision_boundary_simple(svm_model, X, y, "çº¿æ€§SVMå†³ç­–è¾¹ç•Œ")
    
    return svm_model, accuracy

def example_2_nonlinear_classification():
    """
    ç¤ºä¾‹2: éçº¿æ€§åˆ†ç±»ä»»åŠ¡
    
    æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨RBFæ ¸å¤„ç†éçº¿æ€§æ•°æ®
    """
    print("\n" + "="*60)
    print("ç¤ºä¾‹2: éçº¿æ€§åˆ†ç±»ä»»åŠ¡")
    print("="*60)
    
    # 1. ç”Ÿæˆéçº¿æ€§æ•°æ®ï¼ˆåŒå¿ƒåœ†ï¼‰
    print("\nğŸ“Š ç”ŸæˆåŒå¿ƒåœ†æ•°æ®...")
    X, y = SyntheticDataGenerator.generate_circles(
        n_samples=300,
        noise=0.1,
        factor=0.5,
        random_state=42
    )
    
    # å¯è§†åŒ–åŸå§‹æ•°æ®
    visualize_2d_data(X, y, title="åŒå¿ƒåœ†æ•°æ®åˆ†å¸ƒ")
    
    # 2. æ¯”è¾ƒä¸åŒæ ¸å‡½æ•°çš„æ•ˆæœ
    kernels = ['linear', 'rbf', 'poly']
    results = {}
    
    for kernel in kernels:
        print(f"\nğŸ”§ æµ‹è¯• {kernel} æ ¸å‡½æ•°...")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader, val_loader, train_dataset, test_dataset = create_data_loaders(
            X, y, test_size=0.3, batch_size=32, normalize=True
        )
        
        # åˆ›å»ºSVMæ¨¡å‹
        if kernel == 'rbf':
            svm_model = create_svm_model(kernel=kernel, C=1.0, gamma='scale')
        elif kernel == 'poly':
            svm_model = create_svm_model(kernel=kernel, C=1.0, degree=3)
        else:
            svm_model = create_svm_model(kernel=kernel, C=1.0)
        
        # è®­ç»ƒæ¨¡å‹
        X_train = train_dataset.X
        y_train = train_dataset.y
        svm_model.fit(X_train, y_train)
        
        # æµ‹è¯•æ¨¡å‹
        X_test = test_dataset.X
        y_test = test_dataset.y
        predictions = svm_model.predict(X_test)
        accuracy = accuracy_score(y_test.numpy(), predictions.numpy())
        
        results[kernel] = {
            'model': svm_model,
            'accuracy': accuracy
        }
        
        print(f"  - {kernel} æ ¸å‡†ç¡®ç‡: {accuracy:.4f}")
    
    # 3. å¯è§†åŒ–æœ€ä½³æ¨¡å‹çš„å†³ç­–è¾¹ç•Œ
    best_kernel = max(results.keys(), key=lambda k: results[k]['accuracy'])
    best_model = results[best_kernel]['model']
    
    print(f"\nğŸ† æœ€ä½³æ ¸å‡½æ•°: {best_kernel} (å‡†ç¡®ç‡: {results[best_kernel]['accuracy']:.4f})")
    
    visualize_decision_boundary_simple(
        best_model, X, y, 
        f"æœ€ä½³SVMå†³ç­–è¾¹ç•Œ ({best_kernel} æ ¸)"
    )
    
    return results

def example_3_multiclass_classification():
    """
    ç¤ºä¾‹3: å¤šåˆ†ç±»ä»»åŠ¡
    
    æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨SVMè¿›è¡Œå¤šåˆ†ç±»
    """
    print("\n" + "="*60)
    print("ç¤ºä¾‹3: å¤šåˆ†ç±»ä»»åŠ¡")
    print("="*60)
    
    # 1. åŠ è½½çº¢é…’æ•°æ®é›†ï¼ˆ3åˆ†ç±»ï¼‰
    print("\nğŸ· åŠ è½½çº¢é…’æ•°æ®é›†...")
    X, y, feature_names = RealWorldDataLoader.load_wine()
    
    # åˆ†ææ•°æ®é›†
    analyze_dataset(X, y, feature_names)
    
    # 2. åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader, val_loader, train_dataset, test_dataset = create_data_loaders(
        X, y, test_size=0.3, batch_size=32, normalize=True
    )
    
    # 3. åˆ›å»ºå¤šåˆ†ç±»SVM
    print("\nğŸ¤– åˆ›å»ºå¤šåˆ†ç±»SVM...")
    multi_svm = MultiClassSVM(
        kernel='rbf',
        C=1.0,
        gamma='scale'
    )
    
    # è®­ç»ƒæ¨¡å‹
    X_train = train_dataset.X
    y_train = train_dataset.y
    
    print("\nğŸš€ å¼€å§‹è®­ç»ƒå¤šåˆ†ç±»SVM...")
    multi_svm.fit(X_train, y_train)
    
    # 4. è¿›è¡Œé¢„æµ‹
    X_test = test_dataset.X
    y_test = test_dataset.y
    
    predictions = multi_svm.predict(X_test)
    accuracy = accuracy_score(y_test.numpy(), predictions.numpy())
    
    print(f"\nğŸ“ˆ å¤šåˆ†ç±»SVMæ€§èƒ½:")
    print(f"  - æµ‹è¯•å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
    
    # ç”Ÿæˆè¯¦ç»†çš„åˆ†ç±»æŠ¥å‘Š
    class_names = ['Class 0', 'Class 1', 'Class 2']
    report = classification_report(
        y_test.numpy(), 
        predictions.numpy(), 
        target_names=class_names
    )
    print(f"\nğŸ“‹ è¯¦ç»†åˆ†ç±»æŠ¥å‘Š:")
    print(report)
    
    return multi_svm, accuracy

def example_4_parameter_tuning():
    """
    ç¤ºä¾‹4: å‚æ•°è°ƒä¼˜
    
    æ¼”ç¤ºå¦‚ä½•è¿›è¡ŒSVMå‚æ•°è°ƒä¼˜
    """
    print("\n" + "="*60)
    print("ç¤ºä¾‹4: SVMå‚æ•°è°ƒä¼˜")
    print("="*60)
    
    # 1. ç”Ÿæˆæµ‹è¯•æ•°æ®
    print("\nğŸ“Š ç”Ÿæˆæœˆç‰™å½¢æ•°æ®...")
    X, y = SyntheticDataGenerator.generate_moons(
        n_samples=400,
        noise=0.15,
        random_state=42
    )
    
    # å¯è§†åŒ–æ•°æ®
    visualize_2d_data(X, y, title="æœˆç‰™å½¢æ•°æ®åˆ†å¸ƒ")
    
    # 2. åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader, val_loader, train_dataset, test_dataset = create_data_loaders(
        X, y, test_size=0.3, batch_size=32, normalize=True
    )
    
    X_train = train_dataset.X
    y_train = train_dataset.y
    X_test = test_dataset.X
    y_test = test_dataset.y
    
    # 3. å®šä¹‰å‚æ•°ç½‘æ ¼
    print("\nğŸ”§ å®šä¹‰å‚æ•°æœç´¢ç©ºé—´...")
    param_grid = {
        'C': [0.1, 1, 10, 100],           # æ­£åˆ™åŒ–å‚æ•°
        'gamma': [0.001, 0.01, 0.1, 1],   # RBFæ ¸å‚æ•°
    }
    
    best_accuracy = 0
    best_params = {}
    best_model = None
    
    print("\nğŸ” å¼€å§‹ç½‘æ ¼æœç´¢...")
    
    # æ‰‹åŠ¨ç½‘æ ¼æœç´¢ï¼ˆå› ä¸ºæˆ‘ä»¬çš„SVMå®ç°ä¸ç›´æ¥å…¼å®¹sklearnçš„GridSearchCVï¼‰
    for C in param_grid['C']:
        for gamma in param_grid['gamma']:
            print(f"  æµ‹è¯•å‚æ•°: C={C}, gamma={gamma}")
            
            # åˆ›å»ºå¹¶è®­ç»ƒæ¨¡å‹
            svm_model = create_svm_model(
                kernel='rbf',
                C=C,
                gamma=gamma
            )
            
            svm_model.fit(X_train, y_train)
            
            # è¯„ä¼°æ¨¡å‹
            predictions = svm_model.predict(X_test)
            accuracy = accuracy_score(y_test.numpy(), predictions.numpy())
            
            print(f"    å‡†ç¡®ç‡: {accuracy:.4f}")
            
            # æ›´æ–°æœ€ä½³å‚æ•°
            if accuracy > best_accuracy:
                best_accuracy = accuracy
                best_params = {'C': C, 'gamma': gamma}
                best_model = svm_model
    
    # 4. æŠ¥å‘Šæœ€ä½³ç»“æœ
    print(f"\nğŸ† æœ€ä½³å‚æ•°:")
    print(f"  - C: {best_params['C']}")
    print(f"  - gamma: {best_params['gamma']}")
    print(f"  - æœ€ä½³å‡†ç¡®ç‡: {best_accuracy:.4f}")
    
    # 5. å¯è§†åŒ–æœ€ä½³æ¨¡å‹
    visualize_decision_boundary_simple(
        best_model, X, y,
        f"è°ƒä¼˜åçš„SVM (C={best_params['C']}, Î³={best_params['gamma']})"
    )
    
    return best_model, best_params, best_accuracy

def example_5_real_world_application():
    """
    ç¤ºä¾‹5: çœŸå®ä¸–ç•Œåº”ç”¨
    
    ä½¿ç”¨ä¹³è…ºç™Œæ•°æ®é›†æ¼”ç¤ºSVMåœ¨åŒ»ç–—è¯Šæ–­ä¸­çš„åº”ç”¨
    """
    print("\n" + "="*60)
    print("ç¤ºä¾‹5: çœŸå®ä¸–ç•Œåº”ç”¨ - ä¹³è…ºç™Œè¯Šæ–­")
    print("="*60)
    
    # 1. åŠ è½½ä¹³è…ºç™Œæ•°æ®é›†
    print("\nğŸ¥ åŠ è½½ä¹³è…ºç™Œæ•°æ®é›†...")
    X, y, feature_names = RealWorldDataLoader.load_breast_cancer()
    
    # åˆ†ææ•°æ®é›†
    analyze_dataset(X, y, feature_names)
    
    # 2. ä½¿ç”¨å®Œæ•´çš„è®­ç»ƒæµç¨‹
    print("\nğŸš€ ä½¿ç”¨å®Œæ•´è®­ç»ƒæµç¨‹...")
    
    # è¿è¡Œå®Œæ•´å®éªŒ
    model, results = run_svm_experiment(
        dataset_name='cancer',
        kernel='rbf',
        C=1.0,
        gamma='scale'
    )
    
    # 3. åˆ†æç»“æœ
    print(f"\nğŸ¯ åŒ»ç–—è¯Šæ–­ç»“æœåˆ†æ:")
    print(f"  - æ¨¡å‹å‡†ç¡®ç‡: {results['accuracy']:.4f}")
    print(f"  - è¿™æ„å‘³ç€æ¨¡å‹èƒ½æ­£ç¡®è¯Šæ–­ {results['accuracy']*100:.1f}% çš„ç—…ä¾‹")
    
    # è·å–æ”¯æŒå‘é‡ä¿¡æ¯
    sv_info = results['support_vectors_info']
    print(f"  - å…³é”®ç—…ä¾‹æ•°ï¼ˆæ”¯æŒå‘é‡ï¼‰: {sv_info['n_support_vectors']}")
    print(f"  - å…³é”®ç—…ä¾‹æ¯”ä¾‹: {sv_info['support_ratio']:.2f}%")
    
    print("\nğŸ’¡ å®é™…åº”ç”¨å»ºè®®:")
    print("  - åœ¨å®é™…åŒ»ç–—åº”ç”¨ä¸­ï¼Œå»ºè®®ç»“åˆå¤šç§è¯Šæ–­æ–¹æ³•")
    print("  - æ¨¡å‹é¢„æµ‹åº”ä½œä¸ºåŒ»ç”Ÿè¯Šæ–­çš„è¾…åŠ©å·¥å…·")
    print("  - éœ€è¦åœ¨æ›´å¤§è§„æ¨¡çš„æ•°æ®é›†ä¸Šè¿›ä¸€æ­¥éªŒè¯")
    
    return model, results

def visualize_decision_boundary_simple(model, X, y, title):
    """
    ç®€åŒ–çš„å†³ç­–è¾¹ç•Œå¯è§†åŒ–å‡½æ•°
    
    Args:
        model: è®­ç»ƒå¥½çš„SVMæ¨¡å‹
        X: ç‰¹å¾æ•°æ®
        y: æ ‡ç­¾æ•°æ®
        title: å›¾è¡¨æ ‡é¢˜
    """
    if X.shape[1] != 2:
        print(f"è­¦å‘Šï¼šæ•°æ®ç»´åº¦ä¸º{X.shape[1]}ï¼Œæ— æ³•å¯è§†åŒ–å†³ç­–è¾¹ç•Œ")
        return
    
    # åˆ›å»ºç½‘æ ¼
    h = 0.02
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                        np.arange(y_min, y_max, h))
    
    # é¢„æµ‹ç½‘æ ¼ç‚¹
    grid_points = torch.FloatTensor(np.c_[xx.ravel(), yy.ravel()])
    Z = model.decision_function(grid_points)
    Z = Z.detach().numpy().reshape(xx.shape)
    
    # ç»˜åˆ¶å›¾å½¢
    plt.figure(figsize=(10, 8))
    
    # ç»˜åˆ¶å†³ç­–è¾¹ç•Œ
    plt.contourf(xx, yy, Z, levels=50, alpha=0.8, cmap=plt.cm.RdYlBu)
    plt.contour(xx, yy, Z, levels=[0], linewidths=2, colors='black', linestyles='--')
    
    # ç»˜åˆ¶æ•°æ®ç‚¹
    colors = ['red', 'blue']
    for i, color in enumerate(colors):
        mask = y == i
        plt.scatter(X[mask, 0], X[mask, 1], c=color, 
                   label=f'Class {i}', s=50, alpha=0.8, edgecolors='black')
    
    # ç»˜åˆ¶æ”¯æŒå‘é‡
    try:
        support_vectors, _, _ = model.get_support_vectors()
        support_vectors = support_vectors.numpy()
        plt.scatter(support_vectors[:, 0], support_vectors[:, 1],
                   s=200, facecolors='none', edgecolors='black', 
                   linewidths=2, label='Support Vectors')
    except:
        pass
    
    plt.xlabel('Feature 1')
    plt.ylabel('Feature 2')
    plt.title(title)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()

def main():
    """
    ä¸»å‡½æ•°ï¼šè¿è¡Œæ‰€æœ‰ç¤ºä¾‹
    """
    print("ğŸ‰ SVMæ¨¡å‹ä½¿ç”¨ç¤ºä¾‹é›†åˆ")
    print("="*80)
    
    # è®¾ç½®éšæœºç§å­ç¡®ä¿ç»“æœå¯é‡ç°
    torch.manual_seed(42)
    np.random.seed(42)
    
    try:
        # ç¤ºä¾‹1ï¼šåŸºç¡€äºŒåˆ†ç±»
        print("\nğŸš€ è¿è¡Œç¤ºä¾‹1...")
        model1, acc1 = example_1_basic_binary_classification()
        print(f"âœ… ç¤ºä¾‹1å®Œæˆï¼Œå‡†ç¡®ç‡: {acc1:.4f}")
        
        # ç¤ºä¾‹2ï¼šéçº¿æ€§åˆ†ç±»
        print("\nğŸš€ è¿è¡Œç¤ºä¾‹2...")
        results2 = example_2_nonlinear_classification()
        best_acc2 = max(r['accuracy'] for r in results2.values())
        print(f"âœ… ç¤ºä¾‹2å®Œæˆï¼Œæœ€ä½³å‡†ç¡®ç‡: {best_acc2:.4f}")
        
        # ç¤ºä¾‹3ï¼šå¤šåˆ†ç±»
        print("\nğŸš€ è¿è¡Œç¤ºä¾‹3...")
        model3, acc3 = example_3_multiclass_classification()
        print(f"âœ… ç¤ºä¾‹3å®Œæˆï¼Œå‡†ç¡®ç‡: {acc3:.4f}")
        
        # ç¤ºä¾‹4ï¼šå‚æ•°è°ƒä¼˜
        print("\nğŸš€ è¿è¡Œç¤ºä¾‹4...")
        model4, params4, acc4 = example_4_parameter_tuning()
        print(f"âœ… ç¤ºä¾‹4å®Œæˆï¼Œæœ€ä½³å‡†ç¡®ç‡: {acc4:.4f}")
        
        # ç¤ºä¾‹5ï¼šçœŸå®ä¸–ç•Œåº”ç”¨
        print("\nğŸš€ è¿è¡Œç¤ºä¾‹5...")
        model5, results5 = example_5_real_world_application()
        print(f"âœ… ç¤ºä¾‹5å®Œæˆï¼Œå‡†ç¡®ç‡: {results5['accuracy']:.4f}")
        
    except Exception as e:
        print(f"âŒ è¿è¡Œç¤ºä¾‹æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "="*80)
    print("ğŸŠ æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
    print("="*80)
    
    print("\nğŸ“š å­¦ä¹ è¦ç‚¹æ€»ç»“:")
    print("1. çº¿æ€§æ ¸é€‚ç”¨äºçº¿æ€§å¯åˆ†æ•°æ®")
    print("2. RBFæ ¸èƒ½å¤„ç†å¤æ‚çš„éçº¿æ€§æ•°æ®")
    print("3. å‚æ•°Cæ§åˆ¶å¯¹è¯¯åˆ†ç±»çš„å®¹å¿åº¦")
    print("4. å‚æ•°gammaæ§åˆ¶RBFæ ¸çš„å½±å“èŒƒå›´")
    print("5. æ”¯æŒå‘é‡æ˜¯å†³å®šå†³ç­–è¾¹ç•Œçš„å…³é”®æ ·æœ¬")
    print("6. æ•°æ®æ ‡å‡†åŒ–å¯¹SVMæ€§èƒ½å¾ˆé‡è¦")
    print("7. å‚æ•°è°ƒä¼˜èƒ½æ˜¾è‘—æå‡æ¨¡å‹æ€§èƒ½")

if __name__ == "__main__":
    main()